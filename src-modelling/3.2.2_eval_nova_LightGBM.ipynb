{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f860afc-1b50-40a8-9981-70fedcb1046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13d3bbaa-87d9-4619-bc79-fe5e4b2eebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Voorro\\AppData\\Local\\Temp\\ipykernel_26336\\2825167706.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(\"../gen/data_def_train_folds.csv\")\n",
      "C:\\Users\\Voorro\\AppData\\Local\\Temp\\ipykernel_26336\\2825167706.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test  = pd.read_csv(\"../gen/data_def_test.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (206068, 24)\n",
      "Test shape: (88315, 23)\n",
      "Class mapping: {1: 0, 2: 1, 3: 2, 4: 3}\n",
      "\n",
      "==========================================================================================\n",
      "=== phase1_intrinsic – Using column 'labels_1_intrinsic' ===\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:909: UserWarning: unknown class(es) ['ARTIFICIAL_FLAVOR', 'ENRICHED_WITH_OMEGA3', 'HIGH_IN_CARBOHYDRATES', 'HIGH_IN_OMEGA3_AND_OMEGA6', 'HIGH_IN_PROTEIN_AND_FIBRE', 'HIGH_IN_VITAMIN_K', 'KETOGENIC', 'LOW_FODMAP', 'MINIMALLY_PROCESSED', 'NATURAL_SUGARS_FROM_OATS', 'NATURAL_SUGARS_UNALTERED', 'NOT_FROZEN', 'NO_ADDED_ARTIFICIAL_SWEETENERS', 'NO_ADDITIVES_PRESERVATIVES_COLORANTS', 'NO_ANHYDRIDES', 'NO_AROMA_COLORANT_PRESERVATIVE', 'NO_ARTIFICIAL_DYES', 'NO_ARTIFICIAL_E_NUMBERS', 'NO_ARTIFICIAL_PRESERVATIVES_FLAVOURS_DYES', 'NO_CARRAGEENAN', 'NO_CHEMICAL_INGREDIENTS', 'NO_CHEMICAL_TREATMENT', 'NO_CLEANING_AGENTS', 'NO_COLORANT_AROMA_PRESERVATIVE', 'NO_DYES_PRESERVATIVES_HYDROGENATED_FATS', 'NO_EXTRACTS', 'NO_FRUIT', 'NO_GARLIC_ONION', 'NO_GLUTEN_COLORANT_PRESERVATIVE', 'NO_HIGH_PRESSURE_PROCESSING', 'NO_HONEY', 'NO_LARD', 'NO_METAL_MOLD', 'NO_NUT_TRACES', 'NO_PALM_OIL_DERIVATIVES', 'NO_PHOSPHORIC_ACID', 'NO_POTATO_FLAKES', 'NO_PRESERVATIVES_MSG', 'NO_PRESERVATIVE_ARTIFICIAL_COLORANT', 'NO_SOURDOUGH', 'NO_STEROIDS', 'NO_TAURINE', 'RICH_IN_WHOLE_GRAINS', 'SOURCE_OF_POTASSIUM'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label matrix shape (train): (206068, 359)\n",
      "Encoded label matrix shape (test):  (88315, 359)\n",
      "Coverage – phase1_intrinsic:\n",
      "  Train:     80574/206068 (39.101% with ≥1 label in this phase)\n",
      "  Test:      34289/88315 (38.826% with ≥1 label in this phase)\n",
      "  Test-Core: 4875/4876 (99.979% with ≥1 label in this phase)\n",
      "Fitted LightGBM for phase1_intrinsic in 2.53 s\n",
      "Saved feature importance for phase1_intrinsic → ../results/feature_importance/lgb_nova_feature_importance_phase1_intrinsic.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics – phase1_intrinsic\n",
      "Train-Overall: n=206068, Acc=0.5679, BalAcc=0.2835, F1_macro=0.2488\n",
      "Train-PhaseCoverage: n=80574, Acc=0.6631, BalAcc=0.3725, F1_macro=0.3827\n",
      "Test-Overall: n=88315, Acc=0.5676, BalAcc=0.2842, F1_macro=0.2502\n",
      "Test-PhaseCoverage: n=34289, Acc=0.6631, BalAcc=0.3786, F1_macro=0.3920\n",
      "Test-Core: n=4876, Acc=0.6852, BalAcc=0.4113, F1_macro=0.4299\n",
      "\n",
      "==========================================================================================\n",
      "=== phase2_intr+extr – Using column 'labels_1_2_intr_extr' ===\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:909: UserWarning: unknown class(es) ['ARTIFICIAL_FLAVOR', 'CERT_BIODYNAMIC', 'COASTAL_FISHING', 'DLG_BRONZE_MEDAL', 'ENRICHED_WITH_OMEGA3', 'EU_ORGANIC_CERT_FB', 'EU_ORGANIC_CERT_MY', 'GLUTEN_FREE_VEGAN', 'GLUTEN_LACTOSE_SULFITE_FREE', 'HAZELNUT_FREE', 'HIGH_IN_CARBOHYDRATES', 'HIGH_IN_OMEGA3_AND_OMEGA6', 'HIGH_IN_PROTEIN_AND_FIBRE', 'HIGH_IN_VITAMIN_K', 'INVALID_OR_ERROR', 'ISO_50001', 'KETOGENIC', 'LACTOSE_DAIRY_FREE', 'LOW_FODMAP', 'MAY_CONTAIN_SULPHITES', 'MILK_DERIVATIVE_FREE', 'MINIMALLY_PROCESSED', 'NATURAL_SUGARS_FROM_OATS', 'NATURAL_SUGARS_UNALTERED', 'NOT_FROZEN', 'NO_ADDED_ARTIFICIAL_SWEETENERS', 'NO_ADDITIVES_PRESERVATIVES_COLORANTS', 'NO_ANHYDRIDES', 'NO_ANIMAL_INGREDIENTS', 'NO_AROMA_COLORANT_PRESERVATIVE', 'NO_ARTIFICIAL_DYES', 'NO_ARTIFICIAL_E_NUMBERS', 'NO_ARTIFICIAL_PRESERVATIVES_FLAVOURS_DYES', 'NO_CARRAGEENAN', 'NO_CHEMICAL_INGREDIENTS', 'NO_CHEMICAL_TREATMENT', 'NO_CLEANING_AGENTS', 'NO_COLORANT_AROMA_PRESERVATIVE', 'NO_DYES_PRESERVATIVES_HYDROGENATED_FATS', 'NO_EXTRACTS', 'NO_FRUIT', 'NO_GARLIC_ONION', 'NO_GLUTEN_COLORANT_PRESERVATIVE', 'NO_HIGH_PRESSURE_PROCESSING', 'NO_HONEY', 'NO_LARD', 'NO_METAL_MOLD', 'NO_MILK_EGGS', 'NO_MINERAL_NITROGEN_FERTILIZER', 'NO_NUT_TRACES', 'NO_PALM_OIL_DERIVATIVES', 'NO_PHOSPHORIC_ACID', 'NO_POTATO_FLAKES', 'NO_PRESERVATIVES_MSG', 'NO_PRESERVATIVE_ARTIFICIAL_COLORANT', 'NO_PREVENTIVE_ANTIBIOTICS', 'NO_SOURDOUGH', 'NO_STEROIDS', 'NO_TAURINE', 'RICH_IN_WHOLE_GRAINS', 'SOURCE_OF_POTASSIUM', 'WARNING_HIGH_SATURATED_FAT_SODIUM', 'WARNING_INFANTS_UNDER_12M', 'WARNING_NURSING_WOMEN'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label matrix shape (train): (206068, 808)\n",
      "Encoded label matrix shape (test):  (88315, 808)\n",
      "Coverage – phase2_intr+extr:\n",
      "  Train:     185867/206068 (90.197% with ≥1 label in this phase)\n",
      "  Test:      79571/88315 (90.099% with ≥1 label in this phase)\n",
      "  Test-Core: 4876/4876 (100.000% with ≥1 label in this phase)\n",
      "Fitted LightGBM for phase2_intr+extr in 2.98 s\n",
      "Saved feature importance for phase2_intr+extr → ../results/feature_importance/lgb_nova_feature_importance_phase2_intr+extr.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics – phase2_intr+extr\n",
      "Train-Overall: n=206068, Acc=0.6223, BalAcc=0.3818, F1_macro=0.3934\n",
      "Train-PhaseCoverage: n=185867, Acc=0.6237, BalAcc=0.3931, F1_macro=0.4058\n",
      "Test-Overall: n=88315, Acc=0.6178, BalAcc=0.3779, F1_macro=0.3887\n",
      "Test-PhaseCoverage: n=79571, Acc=0.6191, BalAcc=0.3890, F1_macro=0.4012\n",
      "Test-Core: n=4876, Acc=0.7262, BalAcc=0.4526, F1_macro=0.4734\n",
      "\n",
      "==========================================================================================\n",
      "=== phase3_all_labels – Using column 'labels_string' ===\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:909: UserWarning: unknown class(es) ['ARTIFICIAL_FLAVOR', 'CARREFOUR_CLASSIC', 'CERT_BIODYNAMIC', 'COASTAL_FISHING', 'DLG_BRONZE_MEDAL', 'ENRICHED_WITH_OMEGA3', 'EU_ORGANIC_CERT_FB', 'EU_ORGANIC_CERT_MY', 'GLUTEN_FREE_VEGAN', 'GLUTEN_LACTOSE_SULFITE_FREE', 'GOLD_MEDAL_GENERIC', 'GOLD_MEDAL_MILK_GRADE_A', 'HAZELNUT_FREE', 'HIGH_IN_CARBOHYDRATES', 'HIGH_IN_OMEGA3_AND_OMEGA6', 'HIGH_IN_PROTEIN_AND_FIBRE', 'HIGH_IN_VITAMIN_K', 'INVALID_OR_ERROR', 'ISO_50001', 'KETOGENIC', 'LACTOSE_DAIRY_FREE', 'LOW_FODMAP', 'MAY_CONTAIN_SULPHITES', 'MILK_DERIVATIVE_FREE', 'MINIMALLY_PROCESSED', 'NATURAL_SUGARS_FROM_OATS', 'NATURAL_SUGARS_UNALTERED', 'NOT_FROZEN', 'NO_ADDED_ARTIFICIAL_SWEETENERS', 'NO_ADDITIVES_PRESERVATIVES_COLORANTS', 'NO_ANHYDRIDES', 'NO_ANIMAL_INGREDIENTS', 'NO_AROMA_COLORANT_PRESERVATIVE', 'NO_ARTIFICIAL_DYES', 'NO_ARTIFICIAL_E_NUMBERS', 'NO_ARTIFICIAL_PRESERVATIVES_FLAVOURS_DYES', 'NO_CARRAGEENAN', 'NO_CHEMICAL_INGREDIENTS', 'NO_CHEMICAL_TREATMENT', 'NO_CLEANING_AGENTS', 'NO_COLORANT_AROMA_PRESERVATIVE', 'NO_DYES_PRESERVATIVES_HYDROGENATED_FATS', 'NO_EXTRACTS', 'NO_FRUIT', 'NO_GARLIC_ONION', 'NO_GLUTEN_COLORANT_PRESERVATIVE', 'NO_HIGH_PRESSURE_PROCESSING', 'NO_HONEY', 'NO_LARD', 'NO_METAL_MOLD', 'NO_MILK_EGGS', 'NO_MINERAL_NITROGEN_FERTILIZER', 'NO_NUT_TRACES', 'NO_PALM_OIL_DERIVATIVES', 'NO_PHOSPHORIC_ACID', 'NO_POTATO_FLAKES', 'NO_PRESERVATIVES_MSG', 'NO_PRESERVATIVE_ARTIFICIAL_COLORANT', 'NO_PREVENTIVE_ANTIBIOTICS', 'NO_SOURDOUGH', 'NO_STEROIDS', 'NO_TAURINE', 'RICH_IN_WHOLE_GRAINS', 'SAVEURS_D_AILLEURS', 'SAVEUR_INTENSE', 'SAVEUR_JAMBON', 'SOURCE_OF_POTASSIUM', 'WARNING_HIGH_SATURATED_FAT_SODIUM', 'WARNING_INFANTS_UNDER_12M', 'WARNING_NURSING_WOMEN'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label matrix shape (train): (206068, 870)\n",
      "Encoded label matrix shape (test):  (88315, 870)\n",
      "Coverage – phase3_all_labels:\n",
      "  Train:     206068/206068 (100.000% with ≥1 label in this phase)\n",
      "  Test:      88302/88315 (99.985% with ≥1 label in this phase)\n",
      "  Test-Core: 4876/4876 (100.000% with ≥1 label in this phase)\n",
      "Fitted LightGBM for phase3_all_labels in 3.15 s\n",
      "Saved feature importance for phase3_all_labels → ../results/feature_importance/lgb_nova_feature_importance_phase3_all_labels.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "D:\\ProgramFilesFolder\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics – phase3_all_labels\n",
      "Train-Overall: n=206068, Acc=0.6237, BalAcc=0.3841, F1_macro=0.3968\n",
      "Train-PhaseCoverage: n=206068, Acc=0.6237, BalAcc=0.3841, F1_macro=0.3968\n",
      "Test-Overall: n=88315, Acc=0.6187, BalAcc=0.3796, F1_macro=0.3913\n",
      "Test-PhaseCoverage: n=88302, Acc=0.6187, BalAcc=0.3797, F1_macro=0.3913\n",
      "Test-Core: n=4876, Acc=0.7313, BalAcc=0.4724, F1_macro=0.5019\n",
      "\n",
      "=== All Metrics (Train-Overall, Test-Overall, Test-Core, PhaseCoverage) ===\n",
      "                Phase              Dataset  n_samples  Accuracy  \\\n",
      "0    phase1_intrinsic        Train-Overall     206068  0.567919   \n",
      "1    phase1_intrinsic  Train-PhaseCoverage      80574  0.663092   \n",
      "2    phase1_intrinsic         Test-Overall      88315  0.567650   \n",
      "3    phase1_intrinsic   Test-PhaseCoverage      34289  0.663070   \n",
      "4    phase1_intrinsic            Test-Core       4876  0.685193   \n",
      "5    phase2_intr+extr        Train-Overall     206068  0.622280   \n",
      "6    phase2_intr+extr  Train-PhaseCoverage     185867  0.623666   \n",
      "7    phase2_intr+extr         Test-Overall      88315  0.617800   \n",
      "8    phase2_intr+extr   Test-PhaseCoverage      79571  0.619082   \n",
      "9    phase2_intr+extr            Test-Core       4876  0.726210   \n",
      "10  phase3_all_labels        Train-Overall     206068  0.623663   \n",
      "11  phase3_all_labels  Train-PhaseCoverage     206068  0.623663   \n",
      "12  phase3_all_labels         Test-Overall      88315  0.618672   \n",
      "13  phase3_all_labels   Test-PhaseCoverage      88302  0.618695   \n",
      "14  phase3_all_labels            Test-Core       4876  0.731337   \n",
      "\n",
      "    Balanced Accuracy  Precision (Macro)  Recall (Macro)  F1 (Macro)  \\\n",
      "0            0.283469           0.585682        0.283469    0.248800   \n",
      "1            0.372538           0.613415        0.372538    0.382743   \n",
      "2            0.284236           0.606771        0.284236    0.250165   \n",
      "3            0.378557           0.634543        0.378557    0.391978   \n",
      "4            0.411346           0.740983        0.411346    0.429855   \n",
      "5            0.381826           0.610761        0.381826    0.393409   \n",
      "6            0.393110           0.613349        0.393110    0.405823   \n",
      "7            0.377877           0.590003        0.377877    0.388689   \n",
      "8            0.389019           0.592693        0.389019    0.401189   \n",
      "9            0.452577           0.513313        0.452577    0.473434   \n",
      "10           0.384066           0.587290        0.384066    0.396777   \n",
      "11           0.384066           0.587290        0.384066    0.396777   \n",
      "12           0.379636           0.562960        0.379636    0.391258   \n",
      "13           0.379658           0.562971        0.379658    0.391288   \n",
      "14           0.472414           0.599716        0.472414    0.501887   \n",
      "\n",
      "    F1 (Micro)  \n",
      "0     0.567919  \n",
      "1     0.663092  \n",
      "2     0.567650  \n",
      "3     0.663070  \n",
      "4     0.685193  \n",
      "5     0.622280  \n",
      "6     0.623666  \n",
      "7     0.617800  \n",
      "8     0.619082  \n",
      "9     0.726210  \n",
      "10    0.623663  \n",
      "11    0.623663  \n",
      "12    0.618672  \n",
      "13    0.618695  \n",
      "14    0.731337  \n",
      "\n",
      "=== Coverage stats per phase & dataset ===\n",
      "               Phase    Dataset  n_total  n_with_labels  frac_with_labels\n",
      "0   phase1_intrinsic      Train   206068          80574          0.391007\n",
      "1   phase1_intrinsic       Test    88315          34289          0.388258\n",
      "2   phase1_intrinsic  Test-Core     4876           4875          0.999795\n",
      "3   phase2_intr+extr      Train   206068         185867          0.901969\n",
      "4   phase2_intr+extr       Test    88315          79571          0.900991\n",
      "5   phase2_intr+extr  Test-Core     4876           4876          1.000000\n",
      "6  phase3_all_labels      Train   206068         206068          1.000000\n",
      "7  phase3_all_labels       Test    88315          88302          0.999853\n",
      "8  phase3_all_labels  Test-Core     4876           4876          1.000000\n",
      "\n",
      "Files written to ./results/:\n",
      " - lgb_nova_eval_metrics_train_test_core.csv\n",
      " - lgb_nova_phase_coverage_stats.csv\n",
      " - data_def_train_with_lgb_nova_preds.csv\n",
      " - data_def_test_with_lgb_nova_preds.csv\n",
      "Saved combined feature importance for all phases → ../results/feature_importance/lgb_nova_feature_importance_all_phases.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data\n",
    "train = pd.read_csv(\"../gen/data_def_train_folds.csv\")\n",
    "test  = pd.read_csv(\"../gen/data_def_test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "\n",
    "# 2. Create combined column for Phase 2 (intrinsic + extrinsic)\n",
    "train[\"labels_1_2_intr_extr\"] = (\n",
    "    train[[\"labels_1_intrinsic\", \"labels_2_extrinsic\"]]\n",
    "    .fillna(\"\")\n",
    "    .agg(\"|\".join, axis=1)\n",
    "    .str.strip(\"|\")\n",
    ")\n",
    "\n",
    "test[\"labels_1_2_intr_extr\"] = (\n",
    "    test[[\"labels_1_intrinsic\", \"labels_2_extrinsic\"]]\n",
    "    .fillna(\"\")\n",
    "    .agg(\"|\".join, axis=1)\n",
    "    .str.strip(\"|\")\n",
    ")\n",
    "\n",
    "# 3. Target – NOVA group\n",
    "target = \"nova_group\"\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train[target])\n",
    "y_test = le.transform(test[target])\n",
    "\n",
    "print(\"Class mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# 4. Phases and best hyperparameters (per phase)\n",
    "phases = {\n",
    "    \"phase1_intrinsic\": \"labels_1_intrinsic\",\n",
    "    \"phase2_intr+extr\": \"labels_1_2_intr_extr\",\n",
    "    \"phase3_all_labels\": \"labels_string\",\n",
    "}\n",
    "\n",
    "best_params_by_phase = {\n",
    "    \"phase1_intrinsic\": {\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 5,\n",
    "        \"n_estimators\": 300,\n",
    "        \"num_leaves\": 30,\n",
    "    },\n",
    "    \"phase2_intr+extr\": {\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 5,\n",
    "        \"n_estimators\": 300,\n",
    "        \"num_leaves\": 30,\n",
    "    },\n",
    "    \"phase3_all_labels\": {\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\": 5,\n",
    "        \"n_estimators\": 300,\n",
    "        \"num_leaves\": 50,\n",
    "    },\n",
    "}\n",
    "\n",
    "base_lgb_params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": -1,\n",
    "    \"force_row_wise\": True,\n",
    "}\n",
    "\n",
    "# 5. Containers for results\n",
    "all_metrics = []\n",
    "coverage_stats = [] \n",
    "feature_importances = []\n",
    "\n",
    "# 6. Loop over phases – fit/evaluate only\n",
    "for phase_name, label_col in phases.items():\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"=== {phase_name} – Using column '{label_col}' ===\")\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    # 6.1 Encode label features\n",
    "    train[label_col] = train[label_col].fillna(\"\")\n",
    "    test[label_col]  = test[label_col].fillna(\"\")\n",
    "\n",
    "    train_labels = train[label_col].apply(lambda x: x.split(\"|\") if x != \"\" else [])\n",
    "    test_labels  = test[label_col].apply(lambda x: x.split(\"|\") if x != \"\" else [])\n",
    "\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    X_train_labels = mlb.fit_transform(train_labels).astype(np.float32)\n",
    "    X_test_labels  = mlb.transform(test_labels).astype(np.float32)\n",
    "\n",
    "    print(f\"Encoded label matrix shape (train): {X_train_labels.shape}\")\n",
    "    print(f\"Encoded label matrix shape (test):  {X_test_labels.shape}\")\n",
    "\n",
    "    # ---- PhaseCoverage masks (at least 1 label in this phase)\n",
    "    train_nonempty_mask = np.array(X_train_labels.sum(axis=1)).ravel() > 0\n",
    "    test_nonempty_mask  = np.array(X_test_labels.sum(axis=1)).ravel() > 0\n",
    "\n",
    "    # Basic counts for coverage\n",
    "    train_total = len(y_train)\n",
    "    test_total  = len(y_test)\n",
    "    core_mask   = test[\"core_slice\"].astype(bool).values\n",
    "    core_total  = int(core_mask.sum())\n",
    "\n",
    "    train_cov_n = int(train_nonempty_mask.sum())\n",
    "    test_cov_n  = int(test_nonempty_mask.sum())\n",
    "    core_cov_n  = int((test_nonempty_mask & core_mask).sum())\n",
    "\n",
    "    # Store coverage stats\n",
    "    coverage_stats.append({\n",
    "        \"Phase\": phase_name,\n",
    "        \"Dataset\": \"Train\",\n",
    "        \"n_total\": train_total,\n",
    "        \"n_with_labels\": train_cov_n,\n",
    "        \"frac_with_labels\": train_cov_n / train_total if train_total > 0 else np.nan,\n",
    "    })\n",
    "    coverage_stats.append({\n",
    "        \"Phase\": phase_name,\n",
    "        \"Dataset\": \"Test\",\n",
    "        \"n_total\": test_total,\n",
    "        \"n_with_labels\": test_cov_n,\n",
    "        \"frac_with_labels\": test_cov_n / test_total if test_total > 0 else np.nan,\n",
    "    })\n",
    "    coverage_stats.append({\n",
    "        \"Phase\": phase_name,\n",
    "        \"Dataset\": \"Test-Core\",\n",
    "        \"n_total\": core_total,\n",
    "        \"n_with_labels\": core_cov_n,\n",
    "        \"frac_with_labels\": core_cov_n / core_total if core_total > 0 else np.nan,\n",
    "    })\n",
    "\n",
    "    print(\n",
    "        f\"Coverage – {phase_name}:\\n\"\n",
    "        f\"  Train:     {train_cov_n}/{train_total} \"\n",
    "        f\"({train_cov_n/train_total:.3%} with ≥1 label in this phase)\\n\"\n",
    "        f\"  Test:      {test_cov_n}/{test_total} \"\n",
    "        f\"({test_cov_n/test_total:.3%} with ≥1 label in this phase)\\n\"\n",
    "        f\"  Test-Core: {core_cov_n}/{core_total} \"\n",
    "        f\"({core_cov_n/core_total:.3%} with ≥1 label in this phase)\"\n",
    "    )\n",
    "\n",
    "    # 6.2 Fit LightGBM with best params for this phase\n",
    "    lgb_params = {**base_lgb_params, **best_params_by_phase[phase_name]}\n",
    "    lgb = LGBMClassifier(**lgb_params)\n",
    "\n",
    "    fit_start = time.perf_counter()\n",
    "    lgb.fit(X_train_labels, y_train)  # train on ALL rows\n",
    "    fit_end = time.perf_counter()\n",
    "    fit_time = fit_end - fit_start\n",
    "\n",
    "    print(f\"Fitted LightGBM for {phase_name} in {fit_time:.2f} s\")\n",
    "\n",
    "    # 6.3 Feature importance for this phase\n",
    "    feature_names = mlb.classes_\n",
    "\n",
    "    # Split-based importance (default)\n",
    "    imp_split = lgb.feature_importances_.astype(float)\n",
    "\n",
    "    # Gain-based importance via booster\n",
    "    booster = lgb.booster_\n",
    "    imp_gain = booster.feature_importance(importance_type=\"gain\").astype(float)\n",
    "\n",
    "    fi_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"importance_split\": imp_split,\n",
    "        \"importance_gain\": imp_gain,\n",
    "        \"Phase\": phase_name,\n",
    "    })\n",
    "\n",
    "    # Normalized importance\n",
    "    fi_df[\"importance_split_norm\"] = fi_df[\"importance_split\"] / fi_df[\"importance_split\"].sum()\n",
    "    fi_df[\"importance_gain_norm\"]  = fi_df[\"importance_gain\"]  / fi_df[\"importance_gain\"].sum()\n",
    "\n",
    "    # Save per-phase feature importance\n",
    "    os.makedirs(\"../results/feature_importance\", exist_ok=True)\n",
    "    fi_path = f\"../results/feature_importance/lgb_nova_feature_importance_{phase_name}.csv\"\n",
    "    fi_df.to_csv(fi_path, sep=\";\", index=False)\n",
    "    print(f\"Saved feature importance for {phase_name} → {fi_path}\")\n",
    "\n",
    "    feature_importances.append(fi_df)\n",
    "\n",
    "    # 6.4 Predictions: Train–Overall, Test–Overall, Test–Core\n",
    "    # Train–Overall\n",
    "    y_pred_train = lgb.predict(X_train_labels)\n",
    "\n",
    "    # Test–Overall\n",
    "    y_pred_test = lgb.predict(X_test_labels)\n",
    "\n",
    "    # Test–Core subset\n",
    "    y_test_core = y_test[core_mask]\n",
    "    y_pred_test_core = y_pred_test[core_mask]\n",
    "\n",
    "    # PhaseCoverage subsets (at least 1 label in this phase)\n",
    "    y_train_cov = y_train[train_nonempty_mask]\n",
    "    y_pred_train_cov = y_pred_train[train_nonempty_mask]\n",
    "\n",
    "    y_test_cov = y_test[test_nonempty_mask]\n",
    "    y_pred_test_cov = y_pred_test[test_nonempty_mask]\n",
    "\n",
    "    # 6.5 Attach predictions back to DataFrames (model-specific cols)\n",
    "    train[f\"{phase_name}_lgb_pred_enc\"] = y_pred_train\n",
    "    test[f\"{phase_name}_lgb_pred_enc\"] = y_pred_test\n",
    "\n",
    "    train[f\"{phase_name}_lgb_pred\"] = le.inverse_transform(y_pred_train)\n",
    "    test[f\"{phase_name}_lgb_pred\"] = le.inverse_transform(y_pred_test)\n",
    "\n",
    "    # 6.6 Compute metrics\n",
    "    def compute_metrics(y_true, y_pred, phase, dataset_name):\n",
    "        if len(y_true) == 0:\n",
    "            return {\n",
    "                \"Phase\": phase,\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"n_samples\": 0,\n",
    "                \"Accuracy\": np.nan,\n",
    "                \"Balanced Accuracy\": np.nan,\n",
    "                \"Precision (Macro)\": np.nan,\n",
    "                \"Recall (Macro)\": np.nan,\n",
    "                \"F1 (Macro)\": np.nan,\n",
    "                \"F1 (Micro)\": np.nan,\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"Phase\": phase,\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"n_samples\": len(y_true),\n",
    "            \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "            \"Precision (Macro)\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "            \"Recall (Macro)\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "            \"F1 (Macro)\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "            \"F1 (Micro)\": f1_score(y_true, y_pred, average=\"micro\", zero_division=0),\n",
    "        }\n",
    "\n",
    "    # Train metrics\n",
    "    all_metrics.append(compute_metrics(y_train, y_pred_train, phase_name, \"Train-Overall\"))\n",
    "    all_metrics.append(compute_metrics(y_train_cov, y_pred_train_cov, phase_name, \"Train-PhaseCoverage\"))\n",
    "    # Test metrics\n",
    "    all_metrics.append(compute_metrics(y_test, y_pred_test, phase_name, \"Test-Overall\"))\n",
    "    all_metrics.append(compute_metrics(y_test_cov,  y_pred_test_cov,  phase_name, \"Test-PhaseCoverage\"))\n",
    "    all_metrics.append(compute_metrics(y_test_core, y_pred_test_core, phase_name, \"Test-Core\"))\n",
    "\n",
    "    # Print quick summary for this phase (last 5 entries)\n",
    "    print(\"\\nMetrics –\", phase_name)\n",
    "    for m in all_metrics[-5:]:\n",
    "        print(\n",
    "            f\"{m['Dataset']}: n={m['n_samples']}, \"\n",
    "            f\"Acc={m['Accuracy']:.4f}, \"\n",
    "            f\"BalAcc={m['Balanced Accuracy']:.4f}, \"\n",
    "            f\"F1_macro={m['F1 (Macro)']:.4f}\"\n",
    "        )\n",
    "\n",
    "# 7. Combine and inspect metrics across phases & datasets\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "coverage_df = pd.DataFrame(coverage_stats)\n",
    "\n",
    "print(\"\\n=== All Metrics (Train-Overall, Test-Overall, Test-Core, PhaseCoverage) ===\")\n",
    "print(metrics_df)\n",
    "\n",
    "print(\"\\n=== Coverage stats per phase & dataset ===\")\n",
    "print(coverage_df)\n",
    "\n",
    "# 8. Save outputs\n",
    "metrics_df.to_csv(\"../results/lgb_nova_eval_metrics_train_test_core.csv\", sep=\";\", index=False)\n",
    "coverage_df.to_csv(\"../results/lgb_nova_phase_coverage_stats.csv\", sep=\";\", index=False)\n",
    "train.to_csv(\"../results/data_def_train_with_lgb_nova_preds.csv\", sep=\";\", index=False)\n",
    "test.to_csv(\"../results/data_def_test_with_lgb_nova_preds.csv\", sep=\";\", index=False)\n",
    "\n",
    "print(\"\\nFiles written to ./results/:\")\n",
    "print(\" - lgb_nova_eval_metrics_train_test_core.csv\")\n",
    "print(\" - lgb_nova_phase_coverage_stats.csv\")\n",
    "print(\" - data_def_train_with_lgb_nova_preds.csv\")\n",
    "print(\" - data_def_test_with_lgb_nova_preds.csv\")\n",
    "\n",
    "# 9. Combined feature-importance file across phases\n",
    "if feature_importances:\n",
    "    fi_all = pd.concat(feature_importances, ignore_index=True)\n",
    "    fi_all.to_csv(\"../results/feature_importance/lgb_nova_feature_importance_all_phases.csv\",\n",
    "                  sep=\";\", index=False)\n",
    "    print(\"Saved combined feature importance for all phases → \"\n",
    "          \"../results/feature_importance/lgb_nova_feature_importance_all_phases.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
